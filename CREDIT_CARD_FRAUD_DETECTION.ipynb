{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gVL33FhZdXuO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler  # Various sampling techniques\n",
        "from sklearn.linear_model import LogisticRegression  # Example classifier\n",
        "from sklearn.ensemble import RandomForestClassifier  # Example classifier\n",
        "from xgboost import XGBClassifier  # Another powerful classifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Load credit card transaction data\n",
        "df = pd.read_csv('/content/drive/MyDrive/Encryptix/creditcard.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "# Separate features (X) and target variable (y)\n",
        "X = df.drop('Class', axis=1)  # Assuming 'Class' is the fraud label\n",
        "y = df['Class']\n",
        "\n",
        "# Encode categorical features (if any)\n",
        "le = LabelEncoder()\n",
        "for col in X.select_dtypes(include=['object']):\n",
        "    X[col] = le.fit_transform(X[col])\n",
        "\n",
        "# Normalize numerical features (consider normalization or standardization based on data)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "RS6fa2oNufcj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Handle class imbalance if fraud is rare\n",
        "if y_train.value_counts().iloc[1] / y_train.shape[0] < 0.1:\n",
        "    # Adjust threshold based on data\n",
        "    # Tried different oversampling techniques and evaluate their impact\n",
        "    # Here we demonstrate SMOTE and RandomOverSampler\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    ros = RandomOverSampler(random_state=42)\n",
        "    X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "    # Train models with different oversampled datasets and compare performance\n",
        "\n",
        "# Train the classification models (consider multiple models and hyperparameter tuning)\n",
        "model_lr = LogisticRegression(solver='liblinear')  # Example with tuned hyperparameters (replace with tuning code)\n",
        "model_rf = RandomForestClassifier(n_estimators=100, random_state=42)  # Example with tuned hyperparameters\n",
        "model_xgb = XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=100)  # Example with tuned hyperparameters\n",
        "\n",
        "model_lr.fit(X_train, y_train)\n",
        "model_rf.fit(X_train, y_train)\n",
        "model_xgb.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model performance on the testing set (consider various metrics)\n",
        "models = {'Logistic Regression': model_lr, 'Random Forest': model_rf, 'XGBoost': model_xgb}\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred)\n",
        "    print(f'Model: {name}')\n",
        "    print(f'Precision: {precision}')\n",
        "    print(f'Recall: {recall}')\n",
        "    print(f'F1 Score: {f1}')\n",
        "    print(f'ROC AUC: {roc_auc}')\n",
        "    print('-------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPhnykhPukwH",
        "outputId": "3ea7c260-80cf-4ced-b23f-9e272940c65d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Logistic Regression\n",
            "Precision: 0.8636363636363636\n",
            "Recall: 0.5816326530612245\n",
            "F1 Score: 0.6951219512195121\n",
            "ROC AUC: 0.7907371903460314\n",
            "-------------------\n",
            "Model: Random Forest\n",
            "Precision: 0.974025974025974\n",
            "Recall: 0.7653061224489796\n",
            "F1 Score: 0.8571428571428571\n",
            "ROC AUC: 0.8826354754056941\n",
            "-------------------\n",
            "Model: XGBoost\n",
            "Precision: 0.9746835443037974\n",
            "Recall: 0.7857142857142857\n",
            "F1 Score: 0.8700564971751412\n",
            "ROC AUC: 0.892839557038347\n",
            "-------------------\n"
          ]
        }
      ]
    }
  ]
}